---
title: "project_script"
output: html_document
---

##Problem Statement
The goal of your project is to predict the manner in which they did the exercise. This is the "classe" variable in the training set. You may use any of the other variables to predict with. You should create a report describing how you built your model, how you used cross validation, what you think the expected out of sample error is, and why you made the choices you did. You will also use your prediction model to predict 20 different test cases.

Apply your machine learning algorithm to the 20 test cases available in the given test data

##Solution Steps
1- loading required libraries
```{r}
library(ggplot2); library(caret)
```

2- Reading training data and testing data
```{r}
training <- read.csv("pml-training.csv");dim(training)
attach(training)
testing <- read.csv("pml-testing.csv");dim(testing)
summary(training$classe)
```
3- Determine which model to choose to predict "classe" by graphing
some of the predictors in a feature plot.
```{r}
colSelection<- c("roll_belt","pitch_belt", "yaw_belt", "roll_arm", "pitch_arm","yaw_arm")
qplot(roll_belt, roll_forearm, colour=classe, data=training)
```
4- By Viewing the data, we see that some variables do not contribute in our target variable(classe) so let's get rid of them
```{r}
#remove unimportant columns
training <- training[,-c(1:7)]

#remove columns with NAs
training <- training[, colSums(is.na(training))==0]

#remove all columns with factors except the last column (classe)
training<- training[,-which(sapply(training[,1:85], class) == "factor")]
```
5- Cross Validation Using Random Subsampling and Random Forest
```{r}
library(randomForest)
first_seed <- 123355
accuracies <-c()
for (i in 1:3){
  set.seed(first_seed)
  first_seed <- first_seed+1
  trainIndex <- createDataPartition(y=training$classe, p=0.75, list=FALSE)
  trainingSet<- training[trainIndex,]
  testingSet<- training[-trainIndex,]
  modelFit <- randomForest(classe ~., data = trainingSet)
  prediction <- predict(modelFit, testingSet)
  testingSet$rightPred <- prediction == testingSet$classe
  t<-table(prediction, testingSet$classe)
  print(t)
  accuracy <- sum(testingSet$rightPred)/nrow(testingSet)
  accuracies <- c(accuracies,accuracy)
  print(accuracy)
}
accuracies; mean(accuracies)

```
The mean accuracy of these models turned out to be 0.9946302, which is a good estimate of the out of sample error.
6- Applying the Random Forest Model to the 20 Test Cases
```{r}
nrow(testing)
modelFit <- randomForest(classe ~., data = training)
prediction <- predict(modelFit, testing)
prediction
```
